{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T10:52:25.548773Z",
     "start_time": "2025-02-15T10:52:25.545878Z"
    }
   },
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "from pygments.lexers.wgsl import NotLineEndRE\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0, 5001, (1000, 20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4713 2487 3551 ... 1659 4803 4241]\n",
      " [2885  896 3204 ... 1959 1025 1201]\n",
      " [ 641 4656  754 ... 4544 3146 1951]\n",
      " ...\n",
      " [4168 3981 3472 ... 3820 4555 3103]\n",
      " [ 587 1012 2206 ... 3157  633 4331]\n",
      " [4187 1679 4942 ... 1636 2784 4292]]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T10:52:28.641837Z",
     "start_time": "2025-02-15T10:52:28.639237Z"
    }
   },
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "print(ave_cols)\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X, axis=0)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2460.382 2580.953 2525.087 2512.698 2495.421 2508.541 2509.53  2511.635\n",
      " 2536.414 2545.136 2524.099 2552.992 2449.234 2499.77  2465.302 2554.343\n",
      " 2522.436 2465.952 2529.557 2501.54 ]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T10:52:31.060566Z",
     "start_time": "2025-02-15T10:52:31.058079Z"
    }
   },
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T10:52:34.234075Z",
     "start_time": "2025-02-15T10:52:34.231509Z"
    }
   },
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) / std_cols\n",
    "print(X_norm)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.53747873 -0.06391172  0.703816   ... -0.55983211  1.59141687\n",
      "   1.1790424 ]\n",
      " [ 0.2898144  -1.14619274  0.46576058 ... -0.35170371 -1.05319438\n",
      "  -0.88153324]\n",
      " [-1.24178229  1.41155498 -1.21503418 ...  1.44166939  0.43151194\n",
      "  -0.37316754]\n",
      " ...\n",
      " [ 1.16550003  0.95238485  0.64961894 ...  0.93938617  1.41781613\n",
      "   0.40768218]\n",
      " [-1.27863889 -1.0672835  -0.21890602 ...  0.4794224  -1.32759555\n",
      "   1.24004629]\n",
      " [ 1.1784681  -0.61355538  1.6580958  ... -0.57578862  0.17811086\n",
      "   1.21361127]]\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T10:52:36.676879Z",
     "start_time": "2025-02-15T10:52:36.672586Z"
    }
   },
   "source": [
    "# Print the average of all the values of X_norm\n",
    "# You can use either the function or a method. So, there are multiple ways to solve.\n",
    "print(\"The average of all the values of X_norm is: \")\n",
    "print(np.mean(X_norm))\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(\"The average of the minimum value in each column of X_norm is: \")\n",
    "print(X_norm.min(axis = 0).mean())\n",
    "print(np.mean(np.sort(X_norm, axis=0)[0]))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(\"The average of the maximum value in each column of X_norm is: \")\n",
    "print(np.mean(np.sort(X_norm, axis=0)[-1]))\n",
    "print(X_norm.max(axis = 0).mean())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of all the values of X_norm is: \n",
      "-2.939870569207414e-17\n",
      "-2.939870569207414e-17\n",
      "The average of the minimum value in each column of X_norm is: \n",
      "-1.7308058431682896\n",
      "-1.7308058431682896\n",
      "The average of the maximum value in each column of X_norm is: \n",
      "1.7126177756453829\n",
      "1.7126177756453829\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T11:27:46.419943Z",
     "start_time": "2025-02-15T11:27:46.416556Z"
    }
   },
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 4, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T11:47:31.051784Z",
     "start_time": "2025-02-15T11:47:31.048852Z"
    }
   },
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "print(X.shape[0])\n",
    "row_indices = np.random.permutation(X.shape[0])\n",
    "print(row_indices)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[614 464 405 649 993  71 199 237 715 544 511 194 867 393 697 339 808 342\n",
      "  61 994 133 848 846 612 918 135 187 332 555 444  39 481 954 705 136 300\n",
      " 375 314 252 765 234 779 274 597 523 180 921 987 142 742  27 448 813 391\n",
      " 316 403 775 976 925 991 850 319 480 844 764 947 888  47 246 227 861 562\n",
      " 661 858 734 679 730 957 364 371 190 102 197 461 128 698 817 724 177  32\n",
      " 253 595 370 974 193 985 803 605 989 628 543 773 273 459 144 454 590  19\n",
      " 714 384  23 474 278 263 390 893 782 221 290 623 520  46 182 578 677 842\n",
      " 967 132 892 853 807 208 345 315 508 112 757 762 218 106 880 493 851  80\n",
      "  17  59 978 395 174 639 154 515 728 794 368 876 833 258 804 243 951 171\n",
      " 552 616 642 805 446 117 860 878 688 226 373  48 755 610 485 559 955 407\n",
      " 222 923 584 797 353 209  51 695 566 473 449 731 882  44  89 271 113 828\n",
      " 509 320 349 254 159  31  75 796 392 458   1 573 883 522 121 865 239  16\n",
      " 379  60 663 297 772 896 275 953 626 240   2  79 432 699 750 334 979 761\n",
      " 583 166 719 327 475 387 308 645  12 307 977 820 302 897 441 920 984 872\n",
      "  33 777 268 507 525 890 134 280 155 712 630 944  49 108 868 519 118 286\n",
      " 792 167 733 325 440 589 153 631 148  87  91 146 903 924 163 255 411 479\n",
      " 608 894 105 272 707 457 347 115 401 736 586 780  77 436 141 343 506 216\n",
      " 383  29 176 333 716  10 360  22 635 959 217 721  14 568 859 793 531  95\n",
      " 968 881 388   6 581 633  64 899  20 857 205 948 909 173 927  25 648 729\n",
      " 438 396 843 732 495 692 317 119 621  62 786 873 369 152 835 362 627 600\n",
      " 311 321 532 351 292 940 359 617 220 769 204 140  15 747 284 165 380 906\n",
      " 198 988 203  90 822 514   4 837 849 708 922 752 637 200 518 613 161 574\n",
      " 564 686 802  24 181 330 442  42 928 335  78 869 767 549 763 207 288 937\n",
      " 201 492 476 604 357 477 490  58 774 399 982 629 711 877 758 875 463 233\n",
      " 224 179 970 537  73 150  35 229 298  53 437 904 657 412 830 558 723 652\n",
      " 517 694 689 318 659 346 664 768 759 445 406  93 365 158  76 580 691 107\n",
      " 303 845 505 546 625 125 950 671 410 516 585 696 534 210 981 336 855 301\n",
      " 496  38 644 548 917 726 503 856 839 735  88 434 886 930 863 482 185 513\n",
      "  18 941 864 538 433 524 841 366 791 427  36 413 262 527 960 570 829 647\n",
      " 111 678 250 443 195 156 795 261 191 270 110 435 470 756 636 885 257 912\n",
      " 965 248 285 818   9 276 898 800 685 718 306 961 582 946 938 787 812 510\n",
      " 431 426 620 296 452 350 421 749 160 971 323  83  69 189 615 810 430 138\n",
      " 669 460 326 819 530 969   7 312  57 489 528 870 871 963 738 660 825 282\n",
      " 266 638 340 929 905 139 785 766 972 632 521 973 919 279 367 676 591 408\n",
      " 453 554 656 572 168  92 693 986 295 386 622  67 116 744 975 720 674 149\n",
      " 754 244 891 114 551 561 866 238 592 737 966 717 277 571 740 579 103 651\n",
      " 486 283  81 607 361 650 100 540 916 420 816 378 151  82 172 687 913 397\n",
      " 213 542 700 265 104 491 771  55 956 801 293 541 943  98  34 230 911  96\n",
      " 836 123 484 770 329  68 147 400 852 914 127  63 624 143 634 643 358 169\n",
      " 640 363 428 831 563 670 603 672 468 684 264 588 727 683 666 964 322  45\n",
      " 242 170 910 704 824 809 126 539 641 569  30 556 137 494 702 997 188  99\n",
      "  97 382 879 874 806 535 355 545 884 223 901 895 790 668 247 681 291 703\n",
      " 933 606 439 402 998 354 706 575 611 751 487 709 739 214 385 599 760 996\n",
      " 447 781 655 577  40 483 907 289 741  74 472 129 398 469 995 341 164 245\n",
      " 826 665 309 915 814 414 101 783 269 576 215 565 394 999 673 157 184 935\n",
      " 889  11 753 225 499 236 415 594 504  70 416 376 690 926   5 186 788 235\n",
      " 232 466 478 497 305  54 256   3 294 348 196 120 557 653 823 352 902 251\n",
      " 646 682 533 862 952 183 455 942 404 389 847 832 109 854  65 259 934 526\n",
      " 931 789 450 596 745 601 162 701 488 962 419 980 602 377 675 417 553 784\n",
      "  50 175 130 680 502 451 324  28 619 467 299 550 743 945 887 834 231 409\n",
      " 593 501 202 313 337  94 423 422 778 310 799  37 958  66 725 798 211 983\n",
      " 900 331 328  41 609 344 932 228 815 249 949 992 560   0 840 456 598 212\n",
      " 131 746 547 304 939 338 241 462 936 748 908 658 827 425 381 567 260 465\n",
      " 471 529 219 287  43 356 500 206 122 192 512 618 281 713 145 722 990   8\n",
      " 429 424 267 178 662 498 838  21 418 374  52  26 821  72  86  84  13 536\n",
      " 811 710 372 587 776  56 667 654 124  85]\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T11:55:33.389300Z",
     "start_time": "2025-02-15T11:55:33.384841Z"
    }
   },
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "trainStartAndStopIndex = [0, int((len(row_indices) * 0.6))]\n",
    "train = row_indices[np.arange(trainStartAndStopIndex[0], trainStartAndStopIndex[1])]\n",
    "print( train)\n",
    "\n",
    "crossStartAndStop = [train[1]+1, int(train[1]+1 + (len(row_indices) * 0.2))]\n",
    "cross = row_indices[np.arange(crossStartAndStop[0], crossStartAndStop[1])]\n",
    "\n",
    "test_Start_and_Stop = [cross[1]+1, int(cross[1]+1 + (len(row_indices) * 0.2) )]\n",
    "test = row_indices[np.arange(test_Start_and_Stop[0], test_Start_and_Stop[1])]\n",
    "\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X[row_indices[train]]\n",
    "print(X_train.shape)\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X[row_indices[cross]]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X[row_indices[test]]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[614 464 405 649 993  71 199 237 715 544 511 194 867 393 697 339 808 342\n",
      "  61 994 133 848 846 612 918 135 187 332 555 444  39 481 954 705 136 300\n",
      " 375 314 252 765 234 779 274 597 523 180 921 987 142 742  27 448 813 391\n",
      " 316 403 775 976 925 991 850 319 480 844 764 947 888  47 246 227 861 562\n",
      " 661 858 734 679 730 957 364 371 190 102 197 461 128 698 817 724 177  32\n",
      " 253 595 370 974 193 985 803 605 989 628 543 773 273 459 144 454 590  19\n",
      " 714 384  23 474 278 263 390 893 782 221 290 623 520  46 182 578 677 842\n",
      " 967 132 892 853 807 208 345 315 508 112 757 762 218 106 880 493 851  80\n",
      "  17  59 978 395 174 639 154 515 728 794 368 876 833 258 804 243 951 171\n",
      " 552 616 642 805 446 117 860 878 688 226 373  48 755 610 485 559 955 407\n",
      " 222 923 584 797 353 209  51 695 566 473 449 731 882  44  89 271 113 828\n",
      " 509 320 349 254 159  31  75 796 392 458   1 573 883 522 121 865 239  16\n",
      " 379  60 663 297 772 896 275 953 626 240   2  79 432 699 750 334 979 761\n",
      " 583 166 719 327 475 387 308 645  12 307 977 820 302 897 441 920 984 872\n",
      "  33 777 268 507 525 890 134 280 155 712 630 944  49 108 868 519 118 286\n",
      " 792 167 733 325 440 589 153 631 148  87  91 146 903 924 163 255 411 479\n",
      " 608 894 105 272 707 457 347 115 401 736 586 780  77 436 141 343 506 216\n",
      " 383  29 176 333 716  10 360  22 635 959 217 721  14 568 859 793 531  95\n",
      " 968 881 388   6 581 633  64 899  20 857 205 948 909 173 927  25 648 729\n",
      " 438 396 843 732 495 692 317 119 621  62 786 873 369 152 835 362 627 600\n",
      " 311 321 532 351 292 940 359 617 220 769 204 140  15 747 284 165 380 906\n",
      " 198 988 203  90 822 514   4 837 849 708 922 752 637 200 518 613 161 574\n",
      " 564 686 802  24 181 330 442  42 928 335  78 869 767 549 763 207 288 937\n",
      " 201 492 476 604 357 477 490  58 774 399 982 629 711 877 758 875 463 233\n",
      " 224 179 970 537  73 150  35 229 298  53 437 904 657 412 830 558 723 652\n",
      " 517 694 689 318 659 346 664 768 759 445 406  93 365 158  76 580 691 107\n",
      " 303 845 505 546 625 125 950 671 410 516 585 696 534 210 981 336 855 301\n",
      " 496  38 644 548 917 726 503 856 839 735  88 434 886 930 863 482 185 513\n",
      "  18 941 864 538 433 524 841 366 791 427  36 413 262 527 960 570 829 647\n",
      " 111 678 250 443 195 156 795 261 191 270 110 435 470 756 636 885 257 912\n",
      " 965 248 285 818   9 276 898 800 685 718 306 961 582 946 938 787 812 510\n",
      " 431 426 620 296 452 350 421 749 160 971 323  83  69 189 615 810 430 138\n",
      " 669 460 326 819 530 969   7 312  57 489 528 870 871 963 738 660 825 282\n",
      " 266 638 340 929 905 139]\n",
      "(600, 20)\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T11:55:54.062275Z",
     "start_time": "2025-02-15T11:55:54.060102Z"
    }
   },
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
